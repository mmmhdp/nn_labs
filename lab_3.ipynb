{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mmmhdp/nn_labs/blob/main/lab_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0yEBv_wsR6t"
   },
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "1mFeRsqRsCCC"
   },
   "outputs": [],
   "source": [
    "import torch as tr\n",
    "import torchvision as tv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import datetime as dt\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDpUZDvfsSqj"
   },
   "source": [
    "# model stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "Nr9Oc7wr8wV4"
   },
   "outputs": [],
   "source": [
    "mnist_to_lenet_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize(32),\n",
    "])\n",
    "\n",
    "mnist_trainset = tv.datasets.MNIST(root='./data',\n",
    "                                   train=True,\n",
    "                                   download=True,\n",
    "                                   transform=mnist_to_lenet_transforms)\n",
    "mnist_test = tv.datasets.MNIST('./data',\n",
    "                               train=False,\n",
    "                               download=True,\n",
    "                               transform=mnist_to_lenet_transforms)\n",
    "\n",
    "batch_size = 128\n",
    "mnist_train_dataloader = DataLoader(mnist_trainset, batch_size=batch_size)\n",
    "mnist_test_dataloader = DataLoader(mnist_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTRATTvc84j-",
    "outputId": "e459bf28-7298-4821-a837-06f429407084"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset MNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ./data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                  ToImage()\n",
       "                  Resize(size=[32], interpolation=InterpolationMode.BILINEAR, antialias=warn)\n",
       "            ),\n",
       " Dataset MNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                  ToImage()\n",
       "                  Resize(size=[32], interpolation=InterpolationMode.BILINEAR, antialias=warn)\n",
       "            ))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainset, mnist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4n1FvC5B-H1z",
    "outputId": "0fcd3074-42cc-45e7-c2cb-ca1b9383ccc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): Tanh()\n",
       "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (4): Tanh()\n",
       "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (7): Flatten(start_dim=1, end_dim=-1)\n",
       "  (8): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (9): Tanh()\n",
       "  (10): Linear(in_features=84, out_features=10, bias=True)\n",
       "  (11): ReLU()\n",
       "  (12): Linear(in_features=10, out_features=256, bias=True)\n",
       "  (13): ReLU()\n",
       "  (14): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (15): ReLU()\n",
       "  (16): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (17): ReLU()\n",
       "  (18): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nclasses = 10\n",
    "finelenet = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, padding=0),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(2, stride=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(2, stride=2),\n",
    "            nn.Conv2d(16, 120, kernel_size=5),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(84, 10),\n",
    "\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, nclasses),\n",
    "            )\n",
    "\n",
    "finelenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "mcWxRyWvSY-0",
    "outputId": "f93d6034-4538-4b54-c82e-1b89046368ba"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-2ada694311d8>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_amount = 100\n",
    "\n",
    "network = finelenet\n",
    "opt = tr.optim.RMSprop(network.parameters(), lr=1e-5)\n",
    "sch = tr.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=10)\n",
    "device = tr.device(\"cuda\") if tr.cuda.is_available() else tr.device(\"cpu\")\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "\n",
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = tr.Tensor([0]), 0\n",
    "    for X, y in data_iter:\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n\n",
    "\n",
    "\n",
    "for epoch in range(epoch_amount):\n",
    "    network.train()\n",
    "\n",
    "    for features_batch, target_batch in mnist_train_dataloader:\n",
    "        opt.zero_grad()\n",
    "\n",
    "        features_batch = features_batch.to(device).float()\n",
    "        target_batch = target_batch.to(device)\n",
    "\n",
    "        pred_target = network(features_batch)\n",
    "\n",
    "        loss = loss_f(pred_target, target_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        sch.step()\n",
    "\n",
    "    network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "ouL4b0jxmd53"
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(mnist_test_dataloader))\n",
    "pr_x = network(x.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpdENUFRm1JO",
    "outputId": "0fbeeea8-f974-4551-c4dd-0b019bbd681a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84375"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y, y_pred=tr.tensor([tr.argmax(el).item() for el in pr_x]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOMUhW+TKVDktfkcP4R9AoZ",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
